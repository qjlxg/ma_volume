import pandas as pd
import os
import glob
import re # å¯¼å…¥æ­£åˆ™è¡¨è¾¾å¼åº“ç”¨äºSTæ’é™¤
from datetime import datetime
import pytz
import multiprocessing as mp

# --- é…ç½® ---
STOCK_DATA_DIR = 'stock_data'
STOCK_NAMES_FILE = 'stock_names.csv'
MIN_CLOSE_PRICE = 5.0
MAX_CLOSE_PRICE = 20.0 # æ–°å¢ä¸Šé™è¿‡æ»¤

# è®¾ç½®ä¸Šæµ·æ—¶åŒº
SH_TZ = pytz.timezone('Asia/Shanghai')

# å®šä¹‰ä¸­æ–‡åˆ—ååˆ°è‹±æ–‡æ ‡å‡†åˆ—åçš„æ˜ å°„ (åŸºäºç”¨æˆ·æä¾›çš„æ ¼å¼)
COLUMN_MAPPING = {
    'æ—¥æœŸ': 'Date',
    'å¼€ç›˜': 'Open',
    'æ”¶ç›˜': 'Close',
    'æœ€é«˜': 'High',
    'æœ€ä½': 'Low',
    'æˆäº¤é‡': 'Volume',
    'æˆäº¤é¢': 'Amount',
    'è‚¡ç¥¨ä»£ç ': 'Code' 
}

def is_stacked_multi_cannon(df):
    """
    åˆ¤æ–­ K çº¿æ•°æ®ï¼ˆä¾èµ–äºé‡å‘½ååçš„è‹±æ–‡åˆ—åï¼šOpen, Close, High, Lowï¼‰æ˜¯å¦å½¢æˆäº†
    â€œå å½¢å¤šæ–¹ç‚®â€å½¢æ€ã€‚
    
    ï¼ˆå½¢æ€é‡åŒ–é€»è¾‘ä¿æŒä¸å˜ï¼‰
    """
    if len(df) < 4:
        return False

    # å–æœ€è¿‘çš„ 4 æ ¹ K çº¿
    df_recent = df.iloc[-4:]
    
    # æ£€æŸ¥æ‰€æœ‰å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_cols = ['Open', 'Close', 'High', 'Low']
    if not all(col in df_recent.columns for col in required_cols):
        return False
    
    O, C, H, L = df_recent['Open'].values, df_recent['Close'].values, df_recent['High'].values, df_recent['Low'].values
    
    # K1, K2, K3, K4 çš„ç´¢å¼•æ˜¯ 0, 1, 2, 3

    # 1. K2 å’Œ K3 å¿…é¡»æ˜¯é˜³çº¿ï¼ˆClose > Openï¼‰
    is_k2_up = C[1] > O[1]
    is_k3_up = C[2] > O[2]
    if not (is_k2_up and is_k3_up):
        return False

    # 2. K4 å¿…é¡»æ˜¯çªç ´å¤§é˜³çº¿ï¼ˆClose > Openï¼‰
    is_k4_up = C[3] > O[3]
    if not is_k4_up:
        return False

    # 3. K2, K3 å½¢æˆæ•´ç†æˆ–å å‡ï¼Œå®ä½“ç›¸å¯¹è¾ƒå°
    k2_body_size = abs(C[1] - O[1])
    k3_body_size = abs(C[2] - O[2])
    k4_body_size = abs(C[3] - O[3])
    
    if not (k2_body_size < 0.5 * k4_body_size and k3_body_size < 0.5 * k4_body_size):
        return False

    # 4. K4 çªç ´ K1, K2, K3 çš„æœ€é«˜ä»·
    max_prev_high = max(H[0], H[1], H[2])
    
    # K4 çš„æ”¶ç›˜ä»·å¿…é¡»çªç ´å‰ä¸‰æ ¹ K çº¿çš„æœ€é«˜ä»·
    if C[3] <= max_prev_high:
        return False
        
    # 5. K4 çš„æœ€æ–°æ”¶ç›˜ä»·è¿‡æ»¤ (æ–°å¢ä¸Šé™)
    latest_close = C[3]
    if not (MIN_CLOSE_PRICE <= latest_close <= MAX_CLOSE_PRICE):
        return False

    return True


def process_single_file(file_path):
    """å¤„ç†å•ä¸ªè‚¡ç¥¨æ•°æ®æ–‡ä»¶ï¼Œæ£€æŸ¥å½¢æ€å¹¶è¿”å›ä»£ç ï¼ˆå¦‚æœç¬¦åˆï¼‰"""
    stock_code = os.path.basename(file_path).split('.')[0]
    
    # æ’é™¤ 30 å¼€å¤´çš„è‚¡ç¥¨ä»£ç  (åˆ›ä¸šæ¿)
    if stock_code.startswith('30'):
        return None
        
    # æ’é™¤éæ·±æ²ªAè‚¡ï¼ˆä¸»è¦ä¿ç•™ 60/00 å¼€å¤´ï¼‰ï¼Œä½†ç”±äºæ•°æ®æ–‡ä»¶æ˜¯ä» stock_data è¯»å–çš„ï¼Œ
    # ä¸”å·²æ’é™¤ 30 å¼€å¤´ï¼Œè¿™é‡Œä»…éœ€ç¡®ä¿ä»£ç æ˜¯ 6ä½æ•°å­—å³å¯ã€‚
    # å‡è®¾æ‚¨çš„æ•°æ®ç›®å½•åªåŒ…å«è‚¡ç¥¨æ•°æ®æ–‡ä»¶ã€‚

    try:
        df = pd.read_csv(file_path)
        
        # 1. é‡å‘½ååˆ—ä»¥é€‚åº”è„šæœ¬é€»è¾‘
        df = df.rename(columns=COLUMN_MAPPING)
        
        required_cols = ['Date', 'Open', 'Close', 'High', 'Low']
        if not all(col in df.columns for col in required_cols):
            return None
        
        # 2. è§£ææ—¥æœŸå¹¶æ¸…ç† NaN
        df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
        df = df.dropna(subset=['Date', 'Open', 'Close', 'High', 'Low'])

        # 3. ç¡®ä¿æ•°æ®æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values(by='Date').reset_index(drop=True)
        
        # 4. æ‰§è¡Œå½¢æ€æ£€æŸ¥å’Œæ”¶ç›˜ä»·è¿‡æ»¤
        if is_stacked_multi_cannon(df):
            return stock_code
        
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} å‡ºé”™: {e}")
        
    return None

def filter_st(results_df, names_df):
    """æ’é™¤åç§°ä¸­å«æœ‰ *ST æˆ– ST çš„è‚¡ç¥¨"""
    
    # å°†åç§°æ˜ å°„åˆ°ç»“æœ DataFrame
    name_map = names_df.set_index('code')['name'].to_dict()
    results_df['è‚¡ç¥¨åç§°'] = results_df['è‚¡ç¥¨ä»£ç '].map(name_map)
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è¿‡æ»¤åç§°ä¸­åŒ…å« *ST æˆ– ST çš„è‚¡ç¥¨
    # re.IGNORECASE å¿½ç•¥å¤§å°å†™
    st_mask = results_df['è‚¡ç¥¨åç§°'].apply(lambda x: bool(re.search(r'\*?ST', str(x), re.IGNORECASE)))
    
    filtered_df = results_df[~st_mask]
    
    # ç»Ÿè®¡æ’é™¤æ•°é‡å¹¶è¾“å‡º
    excluded_count = len(results_df) - len(filtered_df)
    if excluded_count > 0:
        print(f"å·²æ ¹æ®åç§°è¿‡æ»¤æ¡ä»¶æ’é™¤ {excluded_count} åª ST/é€€å¸‚é£é™©è‚¡ç¥¨ã€‚")
        
    return filtered_df

def main():
    print(f"--- è‚¡ç¥¨å½¢æ€æ‰«æå™¨å¯åŠ¨ ({datetime.now(SH_TZ).strftime('%Y-%m-%d %H:%M:%S')}) ---")
    
    # 1. æŸ¥æ‰¾æ‰€æœ‰æ•°æ®æ–‡ä»¶
    all_files = glob.glob(os.path.join(STOCK_DATA_DIR, '*.csv'))
    if not all_files:
        print(f"æœªåœ¨ '{STOCK_DATA_DIR}' ç›®å½•ä¸‹æ‰¾åˆ°ä»»ä½• CSV æ–‡ä»¶ã€‚è¯·ç¡®ä¿æ•°æ®å·²ä¸Šä¼ ã€‚")
        return

    # 2. å¹¶è¡Œå¤„ç†æ‰€æœ‰æ–‡ä»¶ (åŒ…å« 30 å¼€å¤´çš„ä»£ç æ’é™¤)
    print(f"å¼€å§‹æ‰«æ {len(all_files)} ä¸ªè‚¡ç¥¨æ–‡ä»¶...")
    pool = mp.Pool(mp.cpu_count())
    found_codes = pool.map(process_single_file, all_files)
    pool.close()
    pool.join()
    
    found_codes = [code for code in found_codes if code is not None]
    
    if not found_codes:
        print("æœªæ‰¾åˆ°ç¬¦åˆ 'å å½¢å¤šæ–¹ç‚®' å½¢æ€ä¸”ç¬¦åˆä»·æ ¼/æ¿å—è¿‡æ»¤æ¡ä»¶çš„è‚¡ç¥¨ã€‚")
        return

    # 3. åŒ¹é…è‚¡ç¥¨åç§°å¹¶æ‰§è¡Œ ST æ’é™¤ (éœ€è¦å…ˆåŠ è½½ names_df)
    print(f"åˆç­›å¾—åˆ° {len(found_codes)} åªè‚¡ç¥¨ï¼Œå¼€å§‹åŒ¹é…åç§°å¹¶æ‰§è¡Œ ST è¿‡æ»¤...")
    try:
        names_df = pd.read_csv(STOCK_NAMES_FILE, dtype={'code': str})
    except Exception as e:
        print(f"è¯»å– '{STOCK_NAMES_FILE}' å¤±è´¥: {e}ã€‚æ— æ³•è¿›è¡Œ ST è¿‡æ»¤ã€‚")
        names_df = pd.DataFrame({'code': [], 'name': []})

    # ç»„ç»‡ç»“æœ DataFrame (ç”¨äº ST è¿‡æ»¤)
    results_df_raw = pd.DataFrame({'è‚¡ç¥¨ä»£ç ': found_codes})
    
    # 4. æ‰§è¡Œ ST è¿‡æ»¤
    results_df = filter_st(results_df_raw, names_df)
    
    if results_df.empty:
        print("ç»è¿‡ ST è¿‡æ»¤åï¼Œæ²¡æœ‰è‚¡ç¥¨ç¬¦åˆæ¡ä»¶ã€‚")
        return
    
    print(f"æœ€ç»ˆç­›é€‰å¾—åˆ° {len(results_df)} åªç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ã€‚")

    # 5. ä¿å­˜ç»“æœ
    now = datetime.now(SH_TZ)
    timestamp_str = now.strftime('%Y%m%d_%H%M%S')
    year_month_dir = now.strftime('%Y/%m')
    
    output_dir = os.path.join('scan_results', year_month_dir)
    os.makedirs(output_dir, exist_ok=True)
    
    output_filename = f'stacked_multi_cannon_{timestamp_str}.csv'
    output_path = os.path.join(output_dir, output_filename)
    
    # ç¡®ä¿ 'è‚¡ç¥¨ä»£ç ' å’Œ 'è‚¡ç¥¨åç§°' åˆ—çš„é¡ºåº
    final_cols = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°']
    results_df[final_cols].to_csv(output_path, index=False, encoding='utf-8')
    print(f"\nğŸ‰ ç­›é€‰ç»“æœå·²æˆåŠŸä¿å­˜åˆ°: {output_path}")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print(f"ä¸»ç¨‹åºè¿è¡Œå¤±è´¥: {e}")
