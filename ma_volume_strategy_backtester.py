import os
import re
import pandas as pd

# è®¾ç½® Pandas é€‰é¡¹ï¼Œæ¶ˆé™¤ FutureWarning
pd.set_option('future.no_silent_downcasting', True)

from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import pytz
import numpy as np

# --- å¸¸é‡å®šä¹‰ ---
STOCK_DATA_DIR = 'stock_data'
# ã€å…³é”®ä¿®æ­£ 1ã€‘ï¼šå°†æœ€å¤§å¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°é™ä½åˆ°å®‰å…¨èŒƒå›´ï¼Œé˜²æ­¢ I/O é˜»å¡
MAX_WORKERS = 4 

# --- ç­–ç•¥å‡½æ•°ï¼šæŒ‡æ ‡è®¡ç®—ä¸ä¿¡å·ç”Ÿæˆ (ä¿æŒä¸å˜) ---

def calculate_indicators(data):
    """è®¡ç®—æ‰€éœ€çš„å‡çº¿ï¼ˆMAï¼‰å’Œæˆäº¤é‡æŒ‡æ ‡ã€‚"""
    data = data.copy() 
    if len(data) < 30: 
        return pd.DataFrame() 
    data['Close'] = pd.to_numeric(data['Close'], errors='coerce')
    data['Volume'] = pd.to_numeric(data['Volume'], errors='coerce')
    data['MA5'] = data['Close'].rolling(window=5).mean()
    data['MA20'] = data['Close'].rolling(window=20).mean()
    return data.dropna()

def check_c1_golden_cross(data):
    """æ£€æŸ¥5æ—¥å‡çº¿é‡‘å‰20æ—¥å‡çº¿ã€‚"""
    if len(data) < 2: return False
    d0 = data.iloc[-1]; d1 = data.iloc[-2]
    golden_cross = (d0['MA5'] > d0['MA20']) and (d1['MA5'] <= d1['MA20'])
    entry_point = d0['Close'] > d0['MA20']
    return golden_cross and entry_point

def check_c4_trend_control(data, max_drawdown=0.15, max_days=30):
    """æ£€æŸ¥è¶‹åŠ¿ä¸é£é™©æ§åˆ¶ã€‚"""
    if len(data) < 30: return False
    ma20_slope = data['MA20'].iloc[-1] - data['MA20'].iloc[-5] 
    is_ma20_up = ma20_slope > 0 
    recent_high = data['Close'].iloc[-max_days:].max()
    current_price = data['Close'].iloc[-1]
    if recent_high == 0: return False
    drawdown = (recent_high - current_price) / recent_high
    is_drawdown_controlled = drawdown <= max_drawdown
    return is_ma20_up and is_drawdown_controlled

def select_stock_logic(data):
    """ç»¼åˆæ‰€æœ‰æ¡ä»¶ï¼Œæ‰§è¡Œé€‰è‚¡é€»è¾‘ã€‚"""
    data = calculate_indicators(data)
    if data.empty: return False
    condition_final = check_c1_golden_cross(data) and check_c4_trend_control(data)
    return condition_final

# --- è¾…åŠ©å‡½æ•°ï¼šå›æµ‹æŒ‡æ ‡è®¡ç®— (ä¿æŒä¸å˜) ---

def calculate_returns(equity_curve):
    """è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡ã€æœ€å¤§å›æ’¤å’Œå¤æ™®æ¯”ç‡ã€‚"""
    if equity_curve.empty or equity_curve.iloc[-1] == 1.0:
        return 0.0, 0.0, 0.0

    returns = equity_curve.pct_change().dropna()
    annual_return = (1 + returns.mean()) ** 252 - 1

    cumulative_max = equity_curve.cummax()
    drawdown = (cumulative_max - equity_curve) / cumulative_max
    max_drawdown = drawdown.max()
    
    annual_volatility = returns.std() * np.sqrt(252)
    sharpe_ratio = annual_return / annual_volatility if annual_volatility != 0 else 0.0

    return annual_return, max_drawdown, sharpe_ratio

# --- å›æµ‹ä¸»æµç¨‹å‡½æ•° (ä¿®æ­£å) ---

def process_file_for_backtest(file_path):
    """è¯»å–å•ä¸ªè‚¡ç¥¨æ–‡ä»¶ï¼Œå¹¶ä¸ºå›æµ‹å¤„ç†æ•°æ®ï¼Œç”Ÿæˆæ¯æ—¥ä¿¡å·ã€‚"""
    try:
        match = re.search(r'(\d{6})\.csv$', file_path)
        if not match: return None

        stock_code = match.group(1)
        
        data = pd.read_csv(
            file_path, 
            header=None, 
            names=['Date', 'Code', 'Open', 'Close', 'High', 'Low', 'Volume', 'Amount', 'Amplitude', 'ChangePct', 'ChangeAmt', 'Turnover'],
            parse_dates=['Date'],
            date_format='%Y-%m-%d'
        )
        
        data = data.sort_values(by='Date').reset_index(drop=True).copy()
        
        data = calculate_indicators(data)
        if data.empty: return None

        data['Signal'] = data.apply(
            lambda row: select_stock_logic(data.loc[:row.name]), axis=1
        )
        data['Signal'] = data['Signal'].shift(1).fillna(False).astype(bool) 
        
        return stock_code, data[['Date', 'Close', 'Signal']]

    except Exception as e:
        print(f"Error processing {file_path} for backtest: {e}") 
        return None

def run_backtest(start_date, end_date):
    """ä¸»å›æµ‹å‡½æ•°ï¼šæ¨¡æ‹ŸæŠ•èµ„ç»„åˆè¡¨ç°ã€‚"""
    
    # 1. æ•°æ®å‡†å¤‡
    # ã€å…³é”®ä¿®æ­£ 2ã€‘ï¼šåœ¨æ‰«ææ–‡ä»¶åˆ—è¡¨å‰å…ˆæ‰“å°ï¼Œç¡®è®¤è„šæœ¬æ˜¯å¦å¡åœ¨æ›´æ—©çš„é˜¶æ®µ
    print(f"Checking directory: {STOCK_DATA_DIR}")
    
    try:
        all_files = [os.path.join(STOCK_DATA_DIR, f) 
                    for f in os.listdir(STOCK_DATA_DIR) 
                    if f.endswith('.csv') and re.match(r'\d{6}\.csv$', f)]
    except FileNotFoundError:
        print(f"Error: Stock data directory '{STOCK_DATA_DIR}' not found. Please ensure data is present.")
        return
        
    if not all_files:
        print("No stock data CSV files found for backtest.")
        return

    total_files = len(all_files)
    print(f"Found {total_files} files. Starting parallel data processing with {MAX_WORKERS} workers...")

    all_data = []
    processed_count = 0
    
    # ä½¿ç”¨ ThreadPoolExecutor å¹¶è¡Œå¤„ç†è‚¡ç¥¨æ–‡ä»¶
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_file = {executor.submit(process_file_for_backtest, file): file for file in all_files}
        
        for future in as_completed(future_to_file):
            result = future.result()
            processed_count += 1
            
            if result:
                all_data.append(result)
            
            # æ‰“å°è¿›åº¦æ—¥å¿—
            if processed_count % 100 == 0 or processed_count == total_files:
                print(f"Processing Progress: {processed_count}/{total_files} files processed ({processed_count/total_files:.1%})")


    if not all_data:
        print("No valid stock data processed.")
        return

    # 2. å‡†å¤‡æ—¥æœŸèŒƒå›´å’Œå‡€å€¼æ›²çº¿
    print(f"\n--- Data Preparation Complete. Valid stocks: {len(all_data)} ---")

    all_dates = sorted(pd.concat([data[1]['Date'] for data in all_data]).unique())
    dates_df = pd.DataFrame({'Date': all_dates})
    dates_df['Date'] = pd.to_datetime(dates_df['Date'])
    
    dates_df = dates_df[
        (dates_df['Date'] >= pd.to_datetime(start_date)) & 
        (dates_df['Date'] <= pd.to_datetime(end_date))
    ].reset_index(drop=True)

    if dates_df.empty:
        print("No trading days found in the specified range.")
        return

    daily_returns = pd.Series(0.0, index=dates_df['Date'])
    stock_data_map = {code: df.set_index('Date') for code, df in all_data}
    
    print(f"\nStarting Backtest simulation from {start_date} to {end_date}...")

    # 3. æ¨¡æ‹Ÿäº¤æ˜“ (ä¸²è¡Œæ‰§è¡Œ)
    for i in range(1, len(dates_df)):
        current_date = dates_df.iloc[i]['Date']
        prev_date = dates_df.iloc[i-1]['Date']
        
        total_daily_return = 0.0
        signal_count = 0
        
        for code, df in stock_data_map.items():
            
            if prev_date in df.index and current_date in df.index:
                
                if df.loc[prev_date, 'Signal']:
                    
                    try:
                        return_pct = df.loc[current_date, 'Close'] / df.loc[prev_date, 'Close'] - 1
                        total_daily_return += return_pct
                        signal_count += 1
                    except:
                         continue
        
        if signal_count > 0:
            daily_returns[current_date] = total_daily_return / signal_count

    # 4. è®¡ç®—å‡€å€¼æ›²çº¿å’ŒæŒ‡æ ‡
    equity_curve = (1 + daily_returns).cumprod().fillna(1.0)
    annual_return, max_drawdown, sharpe_ratio = calculate_returns(equity_curve)

    # 5. è¾“å‡ºç»“æœ
    print("\n" + "="*50)
    print("ğŸ“ˆ **Backtest Results (MA/Volume Strategy)** ğŸ“Š")
    print(f"  Start Date (å¼€å§‹æ—¥æœŸ): {start_date}")
    print(f"  End Date (ç»“æŸæ—¥æœŸ):   {end_date}")
    print("="*50)
    print(f"  Annualized Return (å¹´åŒ–æ”¶ç›Š): {annual_return:.2%}")
    print(f"  Max Drawdown (æœ€å¤§å›æ’¤):       {max_drawdown:.2%}")
    print(f"  Sharpe Ratio (å¤æ™®æ¯”ç‡):      {sharpe_ratio:.2f}")
    print("="*50)
    
    # 6. ä¿å­˜å‡€å€¼æ›²çº¿
    output_df = pd.DataFrame({
        'Date': equity_curve.index, 
        'Equity': equity_curve.values
    })
    
    shanghai_tz = pytz.timezone('Asia/Shanghai')
    now = datetime.now(shanghai_tz)
    output_filename = f"backtest_equity_{now.strftime('%Y%m%d_%H%M%S')}.csv"
    output_path = os.path.join('backtest_results', output_filename)
    os.makedirs('backtest_results', exist_ok=True)
    output_df.to_csv(output_path, index=False)
    print(f"Equity curve saved to: {output_path}")

if __name__ == '__main__':
    shanghai_tz = pytz.timezone('Asia/Shanghai')
    end_date = datetime.now(shanghai_tz).strftime('%Y-%m-%d')
    start_date = '2020-01-01'
    
    run_backtest(start_date, end_date)
